<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGL Advanced Effects with Webcam</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>
</head>
<body>
    <video id="video" style="display: none;"></video>
    <canvas id="glCanvas" width="640" height="480"></canvas>
    <script>
        // Vertex shader (same as before)
        const vertexShaderSource = `
            attribute vec4 a_position;
            attribute vec2 a_texCoord;
            varying vec2 v_texCoord;
            void main() {
                gl_Position = a_position;
                v_texCoord = a_texCoord;
            }
        `;

        // Fragment shader (same as before)
        const fragmentShaderSource = `
            precision highp float;
            uniform sampler2D u_image;
            uniform sampler2D u_mask;
            uniform sampler2D u_flow;
            uniform sampler2D u_fluid;
            uniform vec2 u_textureSize;
            varying vec2 v_texCoord;

            vec4 gaussianBlur(sampler2D image, vec2 uv, vec2 resolution, vec2 direction) {
                vec4 color = vec4(0.0);
                vec2 off1 = vec2(1.3333333333333333) * direction;
                color += texture2D(image, uv) * 0.29411764705882354;
                color += texture2D(image, uv + (off1 / resolution)) * 0.35294117647058826;
                color += texture2D(image, uv - (off1 / resolution)) * 0.35294117647058826;
                return color;
            }

            vec3 refract(vec3 i, vec3 n, float eta) {
                float cosi = dot(-i, n);
                float cost2 = 1.0 - eta * eta * (1.0 - cosi * cosi);
                vec3 t = eta * i + ((eta * cosi - sqrt(abs(cost2))) * n);
                return t * vec3(cost2 > 0.0);
            }

            void main() {
                vec4 mask = texture2D(u_mask, v_texCoord);
                vec4 flowData = texture2D(u_flow, v_texCoord);
                vec4 fluidData = texture2D(u_fluid, v_texCoord);
                
                vec2 flow = (flowData.rg - 0.5) * 2.0;
                vec2 fluidForce = (fluidData.rg - 0.5) * 2.0;
                
                vec2 distortedCoord = v_texCoord + flow * 0.1 + fluidForce * 0.05;
                
                vec3 normal = vec3(fluidForce, 1.0);
                normal = normalize(normal);
                
                vec3 refracted = refract(vec3(0.0, 0.0, -1.0), normal, 1.0 / 1.33);
                vec2 refractedCoord = distortedCoord + refracted.xy * 0.1;
                
                vec4 originalColor = texture2D(u_image, refractedCoord);
                vec4 blurredColor = gaussianBlur(u_image, refractedCoord, u_textureSize, vec2(2.0, 2.0));
                
                gl_FragColor = mix(blurredColor, originalColor, mask.r);
            }
        `;

        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('Shader compile error:', gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        function createProgram(gl, vertexShader, fragmentShader) {
            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);
            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error('Program link error:', gl.getProgramInfoLog(program));
                return null;
            }
            return program;
        }

        async function loadAndPredict(video) {
            const net = await bodyPix.load({
                architecture: 'MobileNetV1',
                outputStride: 16,
                multiplier: 0.75,
                quantBytes: 2
            });
            
            const segmentation = await net.segmentPerson(video, {
                flipHorizontal: false,
                internalResolution: 'medium',
                segmentationThreshold: 0.7
            });
            
            return segmentation;
        }

        function createMaskTexture(gl, segmentation, width, height) {
            const maskTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, maskTexture);
            
            const maskData = new Uint8Array(width * height * 4);
            for (let i = 0; i < segmentation.data.length; i++) {
                const value = segmentation.data[i] ? 255 : 0;
                maskData[i * 4] = value;
                maskData[i * 4 + 1] = value;
                maskData[i * 4 + 2] = value;
                maskData[i * 4 + 3] = 255;
            }
            
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, maskData);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            
            return maskTexture;
        }

        function createOpticalFlowTexture(gl, width, height) {
            const flowTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, flowTexture);
            
            const flowData = new Uint8Array(width * height * 4);
            for (let i = 0; i < flowData.length; i += 4) {
                flowData[i] = 128; // R channel (x flow)
                flowData[i + 1] = 128; // G channel (y flow)
                flowData[i + 2] = 0;
                flowData[i + 3] = 255;
            }
            
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, flowData);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            
            return flowTexture;
        }

        function createFluidTexture(gl, width, height) {
            const fluidTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, fluidTexture);
            
            const fluidData = new Uint8Array(width * height * 4);
            for (let i = 0; i < fluidData.length; i += 4) {
                fluidData[i] = 128; // R channel (x velocity)
                fluidData[i + 1] = 128; // G channel (y velocity)
                fluidData[i + 2] = 0;
                fluidData[i + 3] = 255;
            }
            
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, fluidData);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            
            return fluidTexture;
        }

        async function main() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('glCanvas');
            const gl = canvas.getContext('webgl');

            if (!gl) {
                console.error('WebGL not supported');
                return;
            }

            // Set up WebGL
            const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
            const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
            const program = createProgram(gl, vertexShader, fragmentShader);

            const positionAttributeLocation = gl.getAttribLocation(program, 'a_position');
            const texCoordAttributeLocation = gl.getAttribLocation(program, 'a_texCoord');

            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                -1, -1,
                1, -1,
                -1, 1,
                1, 1,
            ]), gl.STATIC_DRAW);

            const texCoordBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                0, 0,
                1, 0,
                0, 1,
                1, 1,
            ]), gl.STATIC_DRAW);

            // Set up webcam
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                await video.play();
            } catch (error) {
                console.error('Error accessing webcam:', error);
                return;
            }

            // Create textures
            const videoTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, videoTexture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

            const flowTexture = createOpticalFlowTexture(gl, video.videoWidth, video.videoHeight);
            const fluidTexture = createFluidTexture(gl, video.videoWidth, video.videoHeight);

            let maskTexture;

            function render() {
                gl.bindTexture(gl.TEXTURE_2D, videoTexture);
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, video);

                gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
                gl.clearColor(0, 0, 0, 0);
                gl.clear(gl.COLOR_BUFFER_BIT);

                gl.useProgram(program);

                gl.enableVertexAttribArray(positionAttributeLocation);
                gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
                gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);

                gl.enableVertexAttribArray(texCoordAttributeLocation);
                gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
                gl.vertexAttribPointer(texCoordAttributeLocation, 2, gl.FLOAT, false, 0, 0);

                gl.uniform2f(gl.getUniformLocation(program, 'u_textureSize'), video.videoWidth, video.videoHeight);

                gl.activeTexture(gl.TEXTURE0);
                gl.bindTexture(gl.TEXTURE_2D, videoTexture);
                gl.uniform1i(gl.getUniformLocation(program, 'u_image'), 0);

                gl.activeTexture(gl.TEXTURE1);
                gl.bindTexture(gl.TEXTURE_2D, maskTexture || videoTexture);
                gl.uniform1i(gl.getUniformLocation(program, 'u_mask'), 1);

                gl.activeTexture(gl.TEXTURE2);
                gl.bindTexture(gl.TEXTURE_2D, flowTexture);
                gl.uniform1i(gl.getUniformLocation(program, 'u_flow'), 2);

                gl.activeTexture(gl.TEXTURE3);
                gl.bindTexture(gl.TEXTURE_2D, fluidTexture);
                gl.uniform1i(gl.getUniformLocation(program, 'u_fluid'), 3);

                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

                requestAnimationFrame(render);
            }

            // Start rendering
            render();

            // Periodically update person segmentation
            async function updateSegmentation() {
                const segmentation = await loadAndPredict(video);
                maskTexture = createMaskTexture(gl, segmentation, video.videoWidth, video.videoHeight);
                setTimeout(updateSegmentation, 100); // Update every 100ms
            }

            updateSegmentation();
        }

        main();
    </script>
</body>
</html>
